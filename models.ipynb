{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import ViTForImageClassification, ViTFeatureExtractor\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torchvision.datasets import CIFAR100\n",
    "from torchvision.transforms import transforms\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.5.1+cu124\n",
      "CUDA Available: True\n",
      "CUDA Version (PyTorch): 12.4\n",
      "cuDNN Version: 90100\n",
      "GPU Name: NVIDIA GeForce RTX 3050 6GB Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"CUDA Version (PyTorch):\", torch.version.cuda)\n",
    "print(\"cuDNN Version:\", torch.backends.cudnn.version())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision.datasets import CIFAR100\n",
    "from torchvision.transforms import transforms\n",
    "from PIL import Image\n",
    "\n",
    "def prepare_cifar100_dataset(root, output_dir, train=True):\n",
    "    \"\"\"\n",
    "    Prepare CIFAR-100 dataset for YOLO in hidden-object-detection format.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    images_dir = os.path.join(output_dir, 'images')\n",
    "    labels_dir = os.path.join(output_dir, 'labels')\n",
    "    os.makedirs(images_dir, exist_ok=True)\n",
    "    os.makedirs(labels_dir, exist_ok=True)\n",
    "\n",
    "    # Load CIFAR-100 dataset\n",
    "    dataset = CIFAR100(root=root, train=train, download=True)\n",
    "    transform = transforms.Compose([transforms.Resize((640, 640))])\n",
    "\n",
    "    for idx, (image, label) in enumerate(dataset):\n",
    "        # Resize image\n",
    "        image = transform(image)\n",
    "        image_path = os.path.join(images_dir, f\"{idx}.jpg\")\n",
    "        image.save(image_path)\n",
    "\n",
    "        # Generate YOLO label\n",
    "        x_center, y_center = 0.5, 0.5  # Normalized center\n",
    "        box_width, box_height = 1.0, 1.0  # Normalized dimensions\n",
    "        label_path = os.path.join(labels_dir, f\"{idx}.txt\")\n",
    "        with open(label_path, \"w\") as f:\n",
    "            f.write(f\"{label} {x_center} {y_center} {box_width} {box_height}\\n\")\n",
    "\n",
    "    print(f\"Dataset prepared in YOLO format at {output_dir}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Prepare YOLO Training Configuration\n",
    "def prepare_yolo_config(output_dir):\n",
    "    \"\"\"\n",
    "    Generates a YAML file for YOLO training configuration.\n",
    "    \"\"\"\n",
    "    yaml_content = f\"\"\"\n",
    "    path: {output_dir}\n",
    "    train: images\n",
    "    val: images\n",
    "    nc: 100\n",
    "    names: [class_0, class_1, class_2, ..., class_99]  # Replace with actual class names\n",
    "    \"\"\"\n",
    "    config_path = os.path.join(output_dir, \"cifar100.yaml\")\n",
    "    with open(config_path, \"w\") as f:\n",
    "        f.write(yaml_content)\n",
    "    print(f\"YOLO config saved to: {config_path}\")\n",
    "    return config_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# Step 1: Prepare CIFAR-100 in YOLO Format\n",
    "def prepare_cifar100_yolo_format(data_dir, output_dir, num_images_per_class=10000):\n",
    "    \"\"\"\n",
    "    Prepares the CIFAR-100 dataset for YOLO in hidden-object-detection format.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    images_dir = os.path.join(output_dir, 'images')\n",
    "    labels_dir = os.path.join(output_dir, 'labels')\n",
    "    os.makedirs(images_dir, exist_ok=True)\n",
    "    os.makedirs(labels_dir, exist_ok=True)\n",
    "\n",
    "    from torchvision.datasets import CIFAR100\n",
    "    from torchvision.transforms import transforms\n",
    "    from PIL import Image\n",
    "\n",
    "    # Load CIFAR-100\n",
    "    dataset = CIFAR100(root=data_dir, train=True, download=True)\n",
    "    transform = transforms.Compose([transforms.Resize((640, 640))])  # Resize for YOLO compatibility\n",
    "    class_counts = [0] * 100\n",
    "\n",
    "    for idx, (image, label) in enumerate(dataset):\n",
    "        if class_counts[label] >= num_images_per_class:\n",
    "            continue\n",
    "\n",
    "        # Save image\n",
    "        image = transform(image)\n",
    "        image_path = os.path.join(images_dir, f\"{idx}.jpg\")\n",
    "        image.save(image_path)\n",
    "\n",
    "        # Save label\n",
    "        label_path = os.path.join(labels_dir, f\"{idx}.txt\")\n",
    "        with open(label_path, \"w\") as f:\n",
    "            x_center, y_center, width, height = 0.5, 0.5, 1.0, 1.0  # Normalized box for the whole image\n",
    "            f.write(f\"{label} {x_center} {y_center} {width} {height}\\n\")\n",
    "\n",
    "        class_counts[label] += 1\n",
    "        if all(count >= num_images_per_class for count in class_counts):\n",
    "            break\n",
    "\n",
    "    print(f\"Dataset prepared in YOLO format at: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_yolo_config(output_dir):\n",
    "    \"\"\"\n",
    "    Creates a YAML config file for YOLO training.\n",
    "    \"\"\"\n",
    "    # CIFAR-100 class names as placeholders (replace with actual class names if needed)\n",
    "    class_names = [f\"class_{i}\" for i in range(100)]\n",
    "\n",
    "    yaml_content = f\"\"\"\n",
    "    path: {output_dir}\n",
    "    train: images\n",
    "    val: images\n",
    "    nc: 100\n",
    "    names: {class_names}\n",
    "    \"\"\"\n",
    "    config_path = os.path.join(output_dir, \"cifar100.yaml\")\n",
    "    with open(config_path, \"w\") as f:\n",
    "        f.write(yaml_content)\n",
    "    print(f\"YOLO config saved to: {config_path}\")\n",
    "    return config_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Dataset prepared in YOLO format at: ./cifar100_yolo\n",
      "YOLO config saved to: ./cifar100_yolo/cifar100.yaml\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6.25M/6.25M [00:17<00:00, 382kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.34 🚀 Python-3.9.19 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3050 6GB Laptop GPU, 5931MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=./cifar100_yolo/cifar100.yaml, epochs=100, time=None, patience=100, batch=32, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=None, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train4\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Dataset 'cifar100_yolo/cifar100.yaml' error ❌ ./cifar100_yolo/cifar100.yaml 'names' length 4 and 'nc: 100' must match.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSyntaxError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/fall-2024/CV-LAB/i202384_A3/a3_task_updated/lib/python3.9/site-packages/ultralytics/engine/trainer.py:562\u001b[0m, in \u001b[0;36mBaseTrainer.get_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myml\u001b[39m\u001b[38;5;124m\"\u001b[39m} \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetect\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegment\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpose\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    561\u001b[0m }:\n\u001b[0;32m--> 562\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_det_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml_file\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data:\n",
      "File \u001b[0;32m~/Documents/fall-2024/CV-LAB/i202384_A3/a3_task_updated/lib/python3.9/site-packages/ultralytics/data/utils.py:293\u001b[0m, in \u001b[0;36mcheck_det_dataset\u001b[0;34m(dataset, autodownload)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m!=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnc\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mSyntaxError\u001b[39;00m(emojis(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must match.\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m data:\n",
      "\u001b[0;31mSyntaxError\u001b[0m: ./cifar100_yolo/cifar100.yaml 'names' length 4 and 'nc: 100' must match.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m prepare_cifar100_yolo_format(data_dir, output_dir, num_images_per_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m)\n\u001b[1;32m     24\u001b[0m config_path \u001b[38;5;241m=\u001b[39m prepare_yolo_config(output_dir)\n\u001b[0;32m---> 25\u001b[0m \u001b[43mtrain_yolov8\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[27], line 7\u001b[0m, in \u001b[0;36mtrain_yolov8\u001b[0;34m(config_path, model_checkpoint)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mTrains YOLOv8 on the prepared CIFAR-100 dataset.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolov8n.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Load the YOLOv8 nano model (pretrained)\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use GPU if available\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_checkpoint\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining complete.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/fall-2024/CV-LAB/i202384_A3/a3_task_updated/lib/python3.9/site-packages/ultralytics/engine/model.py:796\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    794\u001b[0m     args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt_path\n\u001b[0;32m--> 796\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_smart_load\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrainer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_callbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# manually set model only if not resuming\u001b[39;00m\n\u001b[1;32m    798\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mget_model(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39myaml)\n",
      "File \u001b[0;32m~/Documents/fall-2024/CV-LAB/i202384_A3/a3_task_updated/lib/python3.9/site-packages/ultralytics/engine/trainer.py:133\u001b[0m, in \u001b[0;36mBaseTrainer.__init__\u001b[0;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m check_model_file_from_stem(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mmodel)  \u001b[38;5;66;03m# add suffix, i.e. yolov8n -> yolov8n.pt\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch_distributed_zero_first(LOCAL_RANK):  \u001b[38;5;66;03m# avoid auto-downloading dataset multiple times\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainset, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtestset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Optimization utils init\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/fall-2024/CV-LAB/i202384_A3/a3_task_updated/lib/python3.9/site-packages/ultralytics/engine/trainer.py:566\u001b[0m, in \u001b[0;36mBaseTrainer.get_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml_file\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# for validating 'yolo train data=url.zip' usage\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 566\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(emojis(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclean_url(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m error ❌ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m], data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Dataset 'cifar100_yolo/cifar100.yaml' error ❌ ./cifar100_yolo/cifar100.yaml 'names' length 4 and 'nc: 100' must match."
     ]
    }
   ],
   "source": [
    "# Step 3: Train YOLOv8\n",
    "def train_yolov8(config_path, model_checkpoint=None):\n",
    "    \"\"\"\n",
    "    Trains YOLOv8 on the prepared CIFAR-100 dataset.\n",
    "    \"\"\"\n",
    "    model = YOLO(\"yolov8n.pt\")  # Load the YOLOv8 nano model (pretrained)\n",
    "    model.train(\n",
    "        data=config_path,\n",
    "        epochs=100,\n",
    "        batch=32,\n",
    "        imgsz=640,\n",
    "        device=0,  # Use GPU if available\n",
    "        resume=model_checkpoint\n",
    "    )\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "# Paths\n",
    "data_dir = \"./data\"\n",
    "output_dir = \"./cifar100_yolo\"\n",
    "config_path = os.path.join(output_dir, \"cifar100.yaml\")\n",
    "\n",
    "# Run the process\n",
    "prepare_cifar100_yolo_format(data_dir, output_dir, num_images_per_class=10000)\n",
    "config_path = prepare_yolo_config(output_dir)\n",
    "train_yolov8(config_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ultralytics import YOLO\n",
    "# model = YOLO('yolov8m.pt')\n",
    "\n",
    "\n",
    "# results = model.train(data='CIFAR-100', epochs=50, imgsz=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ultralytics YOLO 🚀, AGPL-3.0 license\n",
    "# # Objects365 dataset https://www.objects365.org/ by Megvii\n",
    "# # Documentation: https://docs.ultralytics.com/datasets/detect/objects365/\n",
    "# # Example usage: yolo train data=Objects365.yaml\n",
    "# # parent\n",
    "# # ├── ultralytics\n",
    "# # └── datasets\n",
    "# #     └── Objects365  ← downloads here (712 GB = 367G data + 345G zips)\n",
    "\n",
    "# # Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]\n",
    "# path: ../datasets/Objects365 # dataset root dir\n",
    "# train: images/train # train images (relative to 'path') 1742289 images\n",
    "# val: images/val # val images (relative to 'path') 80000 images\n",
    "# test: # test images (optional)\n",
    "\n",
    "# # Classes\n",
    "# names:\n",
    "#   0: Person\n",
    "#   1: Sneakers\n",
    "#   2: Chair\n",
    "#   3: Other Shoes\n",
    "#   4: Hat\n",
    "#   5: Car\n",
    "#   6: Lamp\n",
    "#   7: Glasses\n",
    "#   8: Bottle\n",
    "#   9: Desk\n",
    "#   10: Cup\n",
    "#   11: Street Lights\n",
    "#   12: Cabinet/shelf\n",
    "#   13: Handbag/Satchel\n",
    "#   14: Bracelet\n",
    "#   15: Plate\n",
    "#   16: Picture/Frame\n",
    "#   17: Helmet\n",
    "#   18: Book\n",
    "#   19: Gloves\n",
    "#   20: Storage box\n",
    "#   21: Boat\n",
    "#   22: Leather Shoes\n",
    "#   23: Flower\n",
    "#   24: Bench\n",
    "#   25: Potted Plant\n",
    "#   26: Bowl/Basin\n",
    "#   27: Flag\n",
    "#   28: Pillow\n",
    "#   29: Boots\n",
    "#   30: Vase\n",
    "#   31: Microphone\n",
    "#   32: Necklace\n",
    "#   33: Ring\n",
    "#   34: SUV\n",
    "#   35: Wine Glass\n",
    "#   36: Belt\n",
    "#   37: Monitor/TV\n",
    "#   38: Backpack\n",
    "#   39: Umbrella\n",
    "#   40: Traffic Light\n",
    "#   41: Speaker\n",
    "#   42: Watch\n",
    "#   43: Tie\n",
    "#   44: Trash bin Can\n",
    "#   45: Slippers\n",
    "#   46: Bicycle\n",
    "#   47: Stool\n",
    "#   48: Barrel/bucket\n",
    "#   49: Van\n",
    "#   50: Couch\n",
    "#   51: Sandals\n",
    "#   52: Basket\n",
    "#   53: Drum\n",
    "#   54: Pen/Pencil\n",
    "#   55: Bus\n",
    "#   56: Wild Bird\n",
    "#   57: High Heels\n",
    "#   58: Motorcycle\n",
    "#   59: Guitar\n",
    "#   60: Carpet\n",
    "#   61: Cell Phone\n",
    "#   62: Bread\n",
    "#   63: Camera\n",
    "#   64: Canned\n",
    "#   65: Truck\n",
    "#   66: Traffic cone\n",
    "#   67: Cymbal\n",
    "#   68: Lifesaver\n",
    "#   69: Towel\n",
    "#   70: Stuffed Toy\n",
    "#   71: Candle\n",
    "#   72: Sailboat\n",
    "#   73: Laptop\n",
    "#   74: Awning\n",
    "#   75: Bed\n",
    "#   76: Faucet\n",
    "#   77: Tent\n",
    "#   78: Horse\n",
    "#   79: Mirror\n",
    "#   80: Power outlet\n",
    "#   81: Sink\n",
    "#   82: Apple\n",
    "#   83: Air Conditioner\n",
    "#   84: Knife\n",
    "#   85: Hockey Stick\n",
    "#   86: Paddle\n",
    "#   87: Pickup Truck\n",
    "#   88: Fork\n",
    "#   89: Traffic Sign\n",
    "#   90: Balloon\n",
    "#   91: Tripod\n",
    "#   92: Dog\n",
    "#   93: Spoon\n",
    "#   94: Clock\n",
    "#   95: Pot\n",
    "#   96: Cow\n",
    "#   97: Cake\n",
    "#   98: Dining Table\n",
    "#   99: Sheep\n",
    "#   100: Hanger\n",
    "#   101: Blackboard/Whiteboard\n",
    "#   102: Napkin\n",
    "#   103: Other Fish\n",
    "#   104: Orange/Tangerine\n",
    "#   105: Toiletry\n",
    "#   106: Keyboard\n",
    "#   107: Tomato\n",
    "#   108: Lantern\n",
    "#   109: Machinery Vehicle\n",
    "#   110: Fan\n",
    "#   111: Green Vegetables\n",
    "#   112: Banana\n",
    "#   113: Baseball Glove\n",
    "#   114: Airplane\n",
    "#   115: Mouse\n",
    "#   116: Train\n",
    "#   117: Pumpkin\n",
    "#   118: Soccer\n",
    "#   119: Skiboard\n",
    "#   120: Luggage\n",
    "#   121: Nightstand\n",
    "#   122: Tea pot\n",
    "#   123: Telephone\n",
    "#   124: Trolley\n",
    "#   125: Head Phone\n",
    "#   126: Sports Car\n",
    "#   127: Stop Sign\n",
    "#   128: Dessert\n",
    "#   129: Scooter\n",
    "#   130: Stroller\n",
    "#   131: Crane\n",
    "#   132: Remote\n",
    "#   133: Refrigerator\n",
    "#   134: Oven\n",
    "#   135: Lemon\n",
    "#   136: Duck\n",
    "#   137: Baseball Bat\n",
    "#   138: Surveillance Camera\n",
    "#   139: Cat\n",
    "#   140: Jug\n",
    "#   141: Broccoli\n",
    "#   142: Piano\n",
    "#   143: Pizza\n",
    "#   144: Elephant\n",
    "#   145: Skateboard\n",
    "#   146: Surfboard\n",
    "#   147: Gun\n",
    "#   148: Skating and Skiing shoes\n",
    "#   149: Gas stove\n",
    "#   150: Donut\n",
    "#   151: Bow Tie\n",
    "#   152: Carrot\n",
    "#   153: Toilet\n",
    "#   154: Kite\n",
    "#   155: Strawberry\n",
    "#   156: Other Balls\n",
    "#   157: Shovel\n",
    "#   158: Pepper\n",
    "#   159: Computer Box\n",
    "#   160: Toilet Paper\n",
    "#   161: Cleaning Products\n",
    "#   162: Chopsticks\n",
    "#   163: Microwave\n",
    "#   164: Pigeon\n",
    "#   165: Baseball\n",
    "#   166: Cutting/chopping Board\n",
    "#   167: Coffee Table\n",
    "#   168: Side Table\n",
    "#   169: Scissors\n",
    "#   170: Marker\n",
    "#   171: Pie\n",
    "#   172: Ladder\n",
    "#   173: Snowboard\n",
    "#   174: Cookies\n",
    "#   175: Radiator\n",
    "#   176: Fire Hydrant\n",
    "#   177: Basketball\n",
    "#   178: Zebra\n",
    "#   179: Grape\n",
    "#   180: Giraffe\n",
    "#   181: Potato\n",
    "#   182: Sausage\n",
    "#   183: Tricycle\n",
    "#   184: Violin\n",
    "#   185: Egg\n",
    "#   186: Fire Extinguisher\n",
    "#   187: Candy\n",
    "#   188: Fire Truck\n",
    "#   189: Billiards\n",
    "#   190: Converter\n",
    "#   191: Bathtub\n",
    "#   192: Wheelchair\n",
    "#   193: Golf Club\n",
    "#   194: Briefcase\n",
    "#   195: Cucumber\n",
    "#   196: Cigar/Cigarette\n",
    "#   197: Paint Brush\n",
    "#   198: Pear\n",
    "#   199: Heavy Truck\n",
    "#   200: Hamburger\n",
    "#   201: Extractor\n",
    "#   202: Extension Cord\n",
    "#   203: Tong\n",
    "#   204: Tennis Racket\n",
    "#   205: Folder\n",
    "#   206: American Football\n",
    "#   207: earphone\n",
    "#   208: Mask\n",
    "#   209: Kettle\n",
    "#   210: Tennis\n",
    "#   211: Ship\n",
    "#   212: Swing\n",
    "#   213: Coffee Machine\n",
    "#   214: Slide\n",
    "#   215: Carriage\n",
    "#   216: Onion\n",
    "#   217: Green beans\n",
    "#   218: Projector\n",
    "#   219: Frisbee\n",
    "#   220: Washing Machine/Drying Machine\n",
    "#   221: Chicken\n",
    "#   222: Printer\n",
    "#   223: Watermelon\n",
    "#   224: Saxophone\n",
    "#   225: Tissue\n",
    "#   226: Toothbrush\n",
    "#   227: Ice cream\n",
    "#   228: Hot-air balloon\n",
    "#   229: Cello\n",
    "#   230: French Fries\n",
    "#   231: Scale\n",
    "#   232: Trophy\n",
    "#   233: Cabbage\n",
    "#   234: Hot dog\n",
    "#   235: Blender\n",
    "#   236: Peach\n",
    "#   237: Rice\n",
    "#   238: Wallet/Purse\n",
    "#   239: Volleyball\n",
    "#   240: Deer\n",
    "#   241: Goose\n",
    "#   242: Tape\n",
    "#   243: Tablet\n",
    "#   244: Cosmetics\n",
    "#   245: Trumpet\n",
    "#   246: Pineapple\n",
    "#   247: Golf Ball\n",
    "#   248: Ambulance\n",
    "#   249: Parking meter\n",
    "#   250: Mango\n",
    "#   251: Key\n",
    "#   252: Hurdle\n",
    "#   253: Fishing Rod\n",
    "#   254: Medal\n",
    "#   255: Flute\n",
    "#   256: Brush\n",
    "#   257: Penguin\n",
    "#   258: Megaphone\n",
    "#   259: Corn\n",
    "#   260: Lettuce\n",
    "#   261: Garlic\n",
    "#   262: Swan\n",
    "#   263: Helicopter\n",
    "#   264: Green Onion\n",
    "#   265: Sandwich\n",
    "#   266: Nuts\n",
    "#   267: Speed Limit Sign\n",
    "#   268: Induction Cooker\n",
    "#   269: Broom\n",
    "#   270: Trombone\n",
    "#   271: Plum\n",
    "#   272: Rickshaw\n",
    "#   273: Goldfish\n",
    "#   274: Kiwi fruit\n",
    "#   275: Router/modem\n",
    "#   276: Poker Card\n",
    "#   277: Toaster\n",
    "#   278: Shrimp\n",
    "#   279: Sushi\n",
    "#   280: Cheese\n",
    "#   281: Notepaper\n",
    "#   282: Cherry\n",
    "#   283: Pliers\n",
    "#   284: CD\n",
    "#   285: Pasta\n",
    "#   286: Hammer\n",
    "#   287: Cue\n",
    "#   288: Avocado\n",
    "#   289: Hami melon\n",
    "#   290: Flask\n",
    "#   291: Mushroom\n",
    "#   292: Screwdriver\n",
    "#   293: Soap\n",
    "#   294: Recorder\n",
    "#   295: Bear\n",
    "#   296: Eggplant\n",
    "#   297: Board Eraser\n",
    "#   298: Coconut\n",
    "#   299: Tape Measure/Ruler\n",
    "#   300: Pig\n",
    "#   301: Showerhead\n",
    "#   302: Globe\n",
    "#   303: Chips\n",
    "#   304: Steak\n",
    "#   305: Crosswalk Sign\n",
    "#   306: Stapler\n",
    "#   307: Camel\n",
    "#   308: Formula 1\n",
    "#   309: Pomegranate\n",
    "#   310: Dishwasher\n",
    "#   311: Crab\n",
    "#   312: Hoverboard\n",
    "#   313: Meatball\n",
    "#   314: Rice Cooker\n",
    "#   315: Tuba\n",
    "#   316: Calculator\n",
    "#   317: Papaya\n",
    "#   318: Antelope\n",
    "#   319: Parrot\n",
    "#   320: Seal\n",
    "#   321: Butterfly\n",
    "#   322: Dumbbell\n",
    "#   323: Donkey\n",
    "#   324: Lion\n",
    "#   325: Urinal\n",
    "#   326: Dolphin\n",
    "#   327: Electric Drill\n",
    "#   328: Hair Dryer\n",
    "#   329: Egg tart\n",
    "#   330: Jellyfish\n",
    "#   331: Treadmill\n",
    "#   332: Lighter\n",
    "#   333: Grapefruit\n",
    "#   334: Game board\n",
    "#   335: Mop\n",
    "#   336: Radish\n",
    "#   337: Baozi\n",
    "#   338: Target\n",
    "#   339: French\n",
    "#   340: Spring Rolls\n",
    "#   341: Monkey\n",
    "#   342: Rabbit\n",
    "#   343: Pencil Case\n",
    "#   344: Yak\n",
    "#   345: Red Cabbage\n",
    "#   346: Binoculars\n",
    "#   347: Asparagus\n",
    "#   348: Barbell\n",
    "#   349: Scallop\n",
    "#   350: Noddles\n",
    "#   351: Comb\n",
    "#   352: Dumpling\n",
    "#   353: Oyster\n",
    "#   354: Table Tennis paddle\n",
    "#   355: Cosmetics Brush/Eyeliner Pencil\n",
    "#   356: Chainsaw\n",
    "#   357: Eraser\n",
    "#   358: Lobster\n",
    "#   359: Durian\n",
    "#   360: Okra\n",
    "#   361: Lipstick\n",
    "#   362: Cosmetics Mirror\n",
    "#   363: Curling\n",
    "#   364: Table Tennis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5.62M/1.24G [03:25<12:52:42, 28.7kB/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolov8m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# load a pretrained model (recommended for training)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mObjects365.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/fall-2024/CV-LAB/i202384_A3/a3_task_updated/lib/python3.9/site-packages/ultralytics/engine/model.py:796\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    794\u001b[0m     args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt_path\n\u001b[0;32m--> 796\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_smart_load\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrainer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_callbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# manually set model only if not resuming\u001b[39;00m\n\u001b[1;32m    798\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mget_model(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39myaml)\n",
      "File \u001b[0;32m~/Documents/fall-2024/CV-LAB/i202384_A3/a3_task_updated/lib/python3.9/site-packages/ultralytics/engine/trainer.py:133\u001b[0m, in \u001b[0;36mBaseTrainer.__init__\u001b[0;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m check_model_file_from_stem(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mmodel)  \u001b[38;5;66;03m# add suffix, i.e. yolov8n -> yolov8n.pt\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch_distributed_zero_first(LOCAL_RANK):  \u001b[38;5;66;03m# avoid auto-downloading dataset multiple times\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainset, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtestset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Optimization utils init\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/fall-2024/CV-LAB/i202384_A3/a3_task_updated/lib/python3.9/site-packages/ultralytics/engine/trainer.py:562\u001b[0m, in \u001b[0;36mBaseTrainer.get_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     data \u001b[38;5;241m=\u001b[39m check_cls_dataset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata)\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myml\u001b[39m\u001b[38;5;124m\"\u001b[39m} \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetect\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegment\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpose\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    561\u001b[0m }:\n\u001b[0;32m--> 562\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_det_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml_file\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[1;32m    564\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml_file\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# for validating 'yolo train data=url.zip' usage\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/fall-2024/CV-LAB/i202384_A3/a3_task_updated/lib/python3.9/site-packages/ultralytics/data/utils.py:338\u001b[0m, in \u001b[0;36mcheck_det_dataset\u001b[0;34m(dataset, autodownload)\u001b[0m\n\u001b[1;32m    336\u001b[0m     r \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39msystem(s)\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# python script\u001b[39;00m\n\u001b[0;32m--> 338\u001b[0m     \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m dt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mt,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    340\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuccess ✅ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolorstr(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbold\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39mDATASETS_DIR)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m} \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailure \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ❌\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m<string>:28\u001b[0m\n",
      "File \u001b[0;32m~/Documents/fall-2024/CV-LAB/i202384_A3/a3_task_updated/lib/python3.9/site-packages/ultralytics/utils/downloads.py:507\u001b[0m, in \u001b[0;36mdownload\u001b[0;34m(url, dir, unzip, delete, curl, threads, retry, exist_ok)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m u \u001b[38;5;129;01min\u001b[39;00m [url] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(url, (\u001b[38;5;28mstr\u001b[39m, Path)) \u001b[38;5;28;01melse\u001b[39;00m url:\n\u001b[0;32m--> 507\u001b[0m         \u001b[43msafe_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munzip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munzip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelete\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelete\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexist_ok\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/fall-2024/CV-LAB/i202384_A3/a3_task_updated/lib/python3.9/site-packages/ultralytics/utils/downloads.py:341\u001b[0m, in \u001b[0;36msafe_download\u001b[0;34m(url, file, dir, unzip, delete, curl, retry, min_bytes, exist_ok, progress)\u001b[0m\n\u001b[1;32m    339\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 341\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_url_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m request\u001b[38;5;241m.\u001b[39murlopen(url) \u001b[38;5;28;01mas\u001b[39;00m response, TQDM(\n\u001b[1;32m    344\u001b[0m         total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(response\u001b[38;5;241m.\u001b[39mgetheader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Length\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m    345\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    349\u001b[0m         unit_divisor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m,\n\u001b[1;32m    350\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n",
      "File \u001b[0;32m~/Documents/fall-2024/CV-LAB/i202384_A3/a3_task_updated/lib/python3.9/site-packages/torch/hub.py:744\u001b[0m, in \u001b[0;36mdownload_url_to_file\u001b[0;34m(url, dst, hash_prefix, progress)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(\n\u001b[1;32m    737\u001b[0m     total\u001b[38;5;241m=\u001b[39mfile_size,\n\u001b[1;32m    738\u001b[0m     disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m progress,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    741\u001b[0m     unit_divisor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m,\n\u001b[1;32m    742\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m         buffer \u001b[38;5;241m=\u001b[39m \u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mREAD_DATA_CHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    745\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    746\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/http/client.py:463\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;66;03m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[1;32m    462\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(amt)\n\u001b[0;32m--> 463\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b)[:n]\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;66;03m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;66;03m# and self.chunked\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/http/client.py:507\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    502\u001b[0m         b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmemoryview\u001b[39m(b)[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength]\n\u001b[1;32m    504\u001b[0m \u001b[38;5;66;03m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;66;03m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m n \u001b[38;5;129;01mand\u001b[39;00m b:\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/ssl.py:1275\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1272\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1273\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1274\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/ssl.py:1133\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from ultralytics import YOLO\n",
    "\n",
    "# # Load a model\n",
    "# model = YOLO(\"yolov8m.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "# # Train the model\n",
    "# results = model.train(data=\"Objects365.yaml\", epochs=50, imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a3_task_updated",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
